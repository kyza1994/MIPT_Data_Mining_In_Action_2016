{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "МФТИ: Data Mining in Action (осень, 2016)\n",
    "\n",
    "* Дмитрий Персиянов, <dmitry.persiyanov@gmail.com>, https://vk.com/persiyanov\n",
    "* Арсений Ашуха, <ars.ashuha@gmail.com>, https://vk.com/ars.ashuha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Домашнее задание №1: линейные модели, бустинг</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дополнительный материал для выполнения дз**:\n",
    "\n",
    "*Линейные модели*:\n",
    "- Лекция 2, DMIA: https://goo.gl/luURTu\n",
    "- Логистическая регрессия, UFLDL Tutorial: http://ufldl.stanford.edu/tutorial/supervised/LogisticRegression/\n",
    "- Линейная регрессия, UFLDL Tutorial: http://ufldl.stanford.edu/tutorial/supervised/LinearRegression/\n",
    "\n",
    "*Бустинг*:\n",
    "- Hastie, The Elements of Statistical Learning, https://goo.gl/k3wfEU, 10 Boosting and Additive Trees 337\n",
    "- Соколов, Семинары по композиционным методам, https://goo.gl/sn8RyJ, http://goo.gl/ajNTQy\n",
    "\n",
    "\n",
    "\n",
    "**Оформление дз**: \n",
    "- Присылайте выполненное задание на почту ``datamininginaction@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``DMIA2016_fall <направление> <фамилия>_<имя> HW1``, к примеру -- ``DMIA2016_fall trends ivanov_ilya HW1``\n",
    "\n",
    "**Вопросы**:\n",
    "- Задавайте вопросы в issues на гитхабе: https://github.com/vkantor/MIPT_Data_Mining_In_Action_2016/issues\n",
    "- Либо в группу или нам в личные сообщения: https://vk.com/data_mining_in_action\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Overview</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На последней лекции вы узнали про классические модели машинного обучения, которые каждый Data Scientist должен знать и понимать, как они работают.\n",
    "\n",
    "В этом домашнем задании мы предлагаем вам реализовать две модели: одну линейную -- логистическую регрессию, и модель бустинга над деревьями, а также сравнить их качество на одном датасете.\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Part 1: Logistic Regression</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm # interactive progress bar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Знакомство с данными\n",
    "Данные представляют собой выборку отзывов о еде с сайта Амазон. Для них проставлены метки -- положительный или отрицательный отзыв."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110163, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.50074\n",
       "1    0.49926\n",
       "Name: Prediction, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Prediction.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что классы сбалансированы. Можем оценивать качество модели по метрике ```accuracy```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Reviews_Summary</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239071</td>\n",
       "      <td>Michigan Cherries</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>466160</td>\n",
       "      <td>Great Product</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>397133</td>\n",
       "      <td>Ovaltine</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>297146</td>\n",
       "      <td>~</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>292685</td>\n",
       "      <td>Love it!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID    Reviews_Summary  Prediction\n",
       "0  239071  Michigan Cherries           1\n",
       "1  466160      Great Product           1\n",
       "2  397133           Ovaltine           1\n",
       "3  297146                  ~           1\n",
       "4  292685           Love it!           1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Reviews_Summary</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110158</th>\n",
       "      <td>486256</td>\n",
       "      <td>Terrible!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110159</th>\n",
       "      <td>199050</td>\n",
       "      <td>Cheap Coffee, No Banana Flavor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110160</th>\n",
       "      <td>278179</td>\n",
       "      <td>Not as described</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110161</th>\n",
       "      <td>87500</td>\n",
       "      <td>Tastes like a squirt of toothpaste mixed into ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110162</th>\n",
       "      <td>121963</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                    Reviews_Summary  Prediction\n",
       "110158  486256                                          Terrible!           0\n",
       "110159  199050                     Cheap Coffee, No Banana Flavor           0\n",
       "110160  278179                                   Not as described           0\n",
       "110161   87500  Tastes like a squirt of toothpaste mixed into ...           0\n",
       "110162  121963                                       Disappointed           0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "## 2. Извлечение признаков\n",
    "Для решения задачи классификации необходимо преобразовать каждый отзыв (документ) в вектор. Размерность данного вектора будет равна количеству слов используемых в корпусе (все документы). Каждая координата соответствует слову, значение в координает равно количеству раз, слово используется в документе. \n",
    "\n",
    "Для решения данной задачи вам необходимо написать код, который преобразовывает матрицу документов в численную матрицу.\n",
    "\n",
    "Дополнительная информация для решения задачи:\n",
    "\n",
    "- Подробнее про векторное представление документов: http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "- Используйте данный трансформер: http://scikit-learn.org/stable/modules/feature_extraction.html#common-vectorizer-usage\n",
    "- Подробнее про разреженные матрицы: http://docs.scipy.org/doc/scipy-0.14.0/reference/sparse.html\n",
    "- Hashing trick: https://en.wikipedia.org/wiki/Feature_hashing\n",
    "\n",
    "Помните, что все эти трансформеры возвращают ```sparse```-матрицы. Учитывая это и то, что линейные модели достаточно хорошо масштабируются на большое количество фич, можно смело ставить ```n_features``` 1000+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_summaries = list(train_df['Reviews_Summary'].values)\n",
    "review_summaries = [l.lower() for l in review_summaries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['michigan cherries', 'great product', 'ovaltine', '~', 'love it!']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_summaries[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Преобразуйте ```review_summaries``` с помощью ```TfidfVectorizer```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1, max_features=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidfed = vectorizer.fit_transform(review_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tfidfed\n",
    "y = train_df.Prediction.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия -- линейный классификатор, который очень часто используется на практике, например, в кредитном скоринге. Преимущества этой модели -- скорость обучения и предсказания (даже при сотнях тысяч фичей) а также интепретируемость: важные признаки имеют бОльшие по модулю веса. \n",
    "\n",
    "При этом отрицательные веса говорят, что фича важна для определения класса 0, а положительные -- для определения класса 1. Это можно понять, если вспомнить, что разделяющая поверхность линейных моделей, это $w^Tx = 0$, а значение алгоритма есть $a(x) = sign(w^Tx)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем предсказывать сентимент, подготовим данные и сделаем валидационную выборку. Вы ведь теперь знаете, что нужно оценивать качество модели не по обучающей выборке, а по валидационной. Иначе вы переобучитесь, когда будете тюнить гиперпараметры модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** Реализуйте код в модуле ```dmia.classifiers.logistic_regression```.**\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dmia.gradient_check import *\n",
    "from dmia.classifiers import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой ячейке вы можете проверить, правильно ли у вас все работает, прежде чем обучать модель на всех данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: 0.000000 analytic: 0.000000, relative error: nan\n",
      "numerical: 0.000000 analytic: 0.000000, relative error: nan\n",
      "numerical: 0.000000 analytic: 0.000000, relative error: nan\n",
      "numerical: -0.000209 analytic: 0.000000, relative error: 1.000000e+00\n",
      "numerical: 0.000000 analytic: 0.000000, relative error: nan\n",
      "numerical: 0.000000 analytic: 0.000000, relative error: nan\n",
      "numerical: 0.000000 analytic: 0.000000, relative error: nan\n",
      "numerical: 0.000000 analytic: 0.000000, relative error: nan\n",
      "numerical: 0.000000 analytic: 0.000000, relative error: nan\n",
      "numerical: 0.000000 analytic: 0.000000, relative error: nan\n"
     ]
    }
   ],
   "source": [
    "X_train_sample = X_train[:1000]\n",
    "y_train_sample = y_train[:1000]\n",
    "clf = LogisticRegression()\n",
    "clf.w = np.random.randn(X_train_sample.shape[1]+1) * 2\n",
    "loss, grad = clf.loss(LogisticRegression.append_biases(X_train_sample), y_train_sample, 0.0)\n",
    "\n",
    "# Numerically compute the gradient along several randomly chosen dimensions, and\n",
    "# compare them with your analytically computed gradient. The numbers should match\n",
    "# almost exactly along all dimensions.\n",
    "f = lambda w: clf.loss(LogisticRegression.append_biases(X_train_sample), y_train_sample, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, clf.w, grad, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите свою модель на ```X_train, y_train```.\n",
    "\n",
    "Для начала можете взять параметры по умолчанию, и найти оптимальные используя валидацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1000: loss 0.691536\n",
      "iteration 50 / 1000: loss 0.048066\n",
      "iteration 100 / 1000: loss 0.021365\n",
      "iteration 150 / 1000: loss 0.013363\n",
      "iteration 200 / 1000: loss 0.010035\n",
      "iteration 250 / 1000: loss 0.007870\n",
      "iteration 300 / 1000: loss 0.006593\n",
      "iteration 350 / 1000: loss 0.005860\n",
      "iteration 400 / 1000: loss 0.005189\n",
      "iteration 450 / 1000: loss 0.004519\n",
      "iteration 500 / 1000: loss 0.004001\n",
      "iteration 550 / 1000: loss 0.003672\n",
      "iteration 600 / 1000: loss 0.003366\n",
      "iteration 650 / 1000: loss 0.003125\n",
      "iteration 700 / 1000: loss 0.002910\n",
      "iteration 750 / 1000: loss 0.002726\n",
      "iteration 800 / 1000: loss 0.002542\n",
      "iteration 850 / 1000: loss 0.002379\n",
      "iteration 900 / 1000: loss 0.002224\n",
      "iteration 950 / 1000: loss 0.002136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<dmia.classifiers.logistic_regression.LogisticRegression instance at 0x000000000CF2E8C8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.train(X_train, y_train, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на качество на валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1-score = 0.497\n",
      "Test f1-score = 0.504\n"
     ]
    }
   ],
   "source": [
    "print \"Train f1-score = %.3f\" % accuracy_score(y_train, clf.predict(X_train))\n",
    "print \"Test f1-score = %.3f\" % accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуем кривые обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "num_iters = 1\n",
    "\n",
    "for i in tqdm.trange(num_iters):\n",
    "    # Сделайте один шаг градиентного спуска с помощью num_iters=1\n",
    "    clf.train(X_train, y_train)\n",
    "    train_scores.append(accuracy_score(y_train, clf.predict(X_train)))\n",
    "    test_scores.append(accuracy_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(train_scores, 'r', test_scores, 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Задание\n",
    "\n",
    "* Обучите вашу модель **на всех данных**, преобразовав их через ```TfidfVectorizer``` с ```max_features=3000```.\n",
    "\n",
    "* Параметры модели ```learning_rate=1.0, num_iters=1000, batch_size=256, reg=1e-3``` и выведите первые 5 самых важных фичей для класса 1 и 5 фичей для класса 0. Убедитесь, что они коррелируют с вашей интуицией о хороших/плохих отзывах. \n",
    "\n",
    "\n",
    "* Топ позитивных фичей перечислите через запятую под пунктом 1 в письме с кодом.\n",
    "\n",
    "* Топ негативных фичей перечислите через запятую под пунктом 1 в письме с кодом.\n",
    "\n",
    "\n",
    "**Hint:** зная индекс фичи, само слово вы можете получить, используя метод ```vectorizer.get_feature_names()```.\n",
    "\n",
    "**Hint:** ```np.argsort```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Обучите модель\n",
    "clf = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Получите индексы фичей\n",
    "pos_features = ...\n",
    "neg_features = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Выведите слова\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Сравнение с sklearn.linear_model.LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите такую же модель, но из пакета ```sklearn.linear_model``` и убедитесь, что ваша имплементация ничем не хуже (ну или почти не хуже)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = linear_model.LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Train accuracy = %.3f\" % accuracy_score(y_train, clf.predict(X_train))\n",
    "print \"Test accuracy = %.3f\" % accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Что дальше?\n",
    "* Нам повезло, что классы в нашем датасете сбалансированы. Какие проблемы возникнут у логистической регрессии, если, скажем, будет 90% нулевого класса и 10% первого. Как нужно изменить код, чтобы исправить эту проблему? Постарайтесь придумать не менее 2х способов.\n",
    "* Почему мы не делаем регуляризацию для bias term в весах? Может, все таки, в каких-то случаях ее стоит делать?\n",
    "\n",
    "Ответы на вопросы напишите здесь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "<h1 align='center'>Part 2: Boosting</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Градиентный спуск\n",
    "\n",
    "Самый простой метод минимизации функции, для оптимизации в каждый момент времени двигаемся по антиградиенту функции с каким-то шагом. \n",
    "\n",
    "\n",
    "$$w_{n+1} = w_n - s \\cdot \\frac{\\partial f}{\\partial w}$$\n",
    "\n",
    "### Градиентный бустинг\n",
    "\n",
    "Теперь давайте представим, что на каждом шаге мы оптимизируем не параметры алгоритма $w$, а ответы нашего алгоритма $\\hat{y}$.\n",
    "\n",
    "**Обучение**: На каждом шаге, давайте предсказывать градиент на каждом объекте и \"двигать\" ответ в сторону улучшения (антиградиента).\n",
    "\n",
    "**Как в итоге обучать**:\n",
    "- Первый алгоритм отвечает константу \n",
    "- Добавляем базовые алгоритмы $b_i$, $i = 1, .., N$:\n",
    "    - Вычисляем градиент функции потерь ПО ОТВЕТАМ модели $g_{i-1} = \\frac{\\partial L(\\hat{y},~~y)}{\\partial \\hat{y}} = \\frac{\\partial L(\\sum_{j=0}^{i-1} a_j b_j(x),~~y)}{\\partial \\sum_{j=0}^{i-1} a_j b_j(x)}$ на каждом объекте  \n",
    "    - Обучаем $b_i$ предсказывать текущий $g_{i-1}$\n",
    "    - Подбираем $a_i$ -- одномерной минимизацией \n",
    "    - Дополняем композицию $\\sum_{j=0}^{i-1} a_j b_j (x) + a_i b_i(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** Реализуйте код в модуле ```dmia.classifiers.binary_boosting```.**\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dmia.classifiers import BinaryBoostingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from dmia.utils import plot_surface\n",
    "\n",
    "X, y = make_classification(n_samples=500, n_features=2,\n",
    "                           n_informative=2, n_redundant=0, n_repeated=0,\n",
    "                           n_classes=2, n_clusters_per_class=2,\n",
    "                           flip_y=0.05, class_sep=0.8, random_state=241)\n",
    "y = 2*(y-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = BinaryBoostingClassifier(n_estimators=100).fit(X, y)\n",
    "plot_surface(X, y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на выбросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outliers_indices = clf.out_\n",
    "plot_surface(X[outliers_indices], y[outliers_indices], clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы обучали логистическую регрессию на 1000+ фичах и это было быстро.\n",
    "\n",
    "Как вы думаете, разумно ли обучать бустинг над деревьями на 1000 фичах? А на 10000? 100000? Обоснуйте ответ в каждом случае. Если не разумно, то что можно предпринять?\n",
    "\n",
    "Ответ напишите ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = BinaryBoostingClassifier(n_estimators=100, max_depth=3).fit(X_train, y_train)\n",
    "\n",
    "print \"Train accuracy = %.3f\" % accuracy_score(y_train, clf.predict(X_train))\n",
    "print \"Test accuracy = %.3f\" % accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Посмотрим на ```feature_importances_```\n",
    "\n",
    "* Обучите бустинг **на всех данных**, обработав ```review_summaries``` с помощью ```TfidfVectorizer``` с ```max_features=1000```.\n",
    "\n",
    "* Параметры модели возьмите ```lr=0.1, n_estimators=100, max_depth=3```.\n",
    "\n",
    "* Найдите топ-10 самых важных фичей с точки зрения алгоритма.\n",
    "\n",
    "* Перечислите эти 10 слов через запятую под пунктом 3 в своем письме с кодом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidfed = vectorizer.fit_transform(review_summaries)\n",
    "\n",
    "clf = BinaryBoostingClassifier(n_estimators=100, max_depth=3)\n",
    "clf.fit(tfidfed, train_df.Prediction.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_imp_features = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Напечатайте слова\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Сравнение с sklearn.ensemble.GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите градиентный бустинг из ```sklearn``` и сравните его качество на ```X_test``` с вашим (Оно не должно отличаться на много процентов! Вы образали деревья?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Train accuracy = %.3f\" % accuracy_score(y_train, clf.predict(X_train))\n",
    "print \"Test accuracy = %.3f\" % accuracy_score(y_test, clf.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
